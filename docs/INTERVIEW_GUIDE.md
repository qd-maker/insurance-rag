# 保险 RAG 项目面试指南 (2026 暑假实习)

> **定位**: 为 AI 产品经理 / AI 工程师实习面试准备的完整话术与知识点手册  
> **目标**: 稳定表达 + 深度证明 + 产品思维展示  
> **适用场景**: 技术面试、产品面试、HR 面试

---

## 📋 快速自我介绍模板 (30秒版)

> "我是一名网络工程专业大二学生,目前专注于 AI 应用工程方向。
> 
> 最近完成了一个**保险场景的 RAG 信息提取系统**,核心解决销售人员查阅保险条款效率低的问题——将原本 10-30 分钟的条款查阅时间缩短到 10-30 秒。
> 
> 技术栈是 **Next.js + Supabase + OpenAI API**,实现了混合检索、结构化信息提取和可追溯引用。项目已建立完整的测试评估体系,6大核心指标持续监控质量。
> 
> 我的技术风格偏向**快速交付 MVP**,强依赖 AI 工具提效,追求可就业的实战能力而非纯理论。"

---

## 🎯 项目核心亮点 (面试必讲的3个点)

### 亮点 1: UI强约束设计 —— 产品思维的体现

**面试话术**:
> "这个项目最大的设计决策是**用 UI 约束替代复杂的拒答策略**。
> 
> 传统 RAG 系统允许用户自由输入,需要处理大量无效查询、库外产品、恶意输入等边界情况。我们通过前端下拉选择框,让用户只能选择已有产品,从根本上消除了这些问题。
> 
> 这个设计让我们能**聚焦真正重要的质量指标**:引用准确率、结构化抽取完整性、结果稳定性,而不是浪费精力在拒答策略上。
> 
> 这体现了'**约束优于自由**'的产品哲学——通过合理的产品设计,让技术实现更简单、更可控。"

**追问应对**:
- **Q: 为什么不做开放式问答?**  
  A: 业务场景是销售人员需要完整的产品信息卡片,不是回答零散问题。开放式问答会导致回答不完整、用户需要多次提问,反而降低效率。

- **Q: 如果用户想问库外产品怎么办?**  
  A: 产品列表由管理员维护,有明确的产品管理后台。如果需要新产品,走标准的产品添加流程,确保数据质量可控。

---

### 亮点 2: 混合检索策略 —— 技术深度的证明

**面试话术**:
> "在检索策略上,我们实现了**精确匹配 + 语义检索的混合方案**。
> 
> 核心逻辑是:
> 1. **短查询**(产品名)优先用精确匹配,因为产品名信息熵低,纯向量检索容易跨产品污染
> 2. **长查询**(描述性问题)用语义检索,发挥向量的语义理解能力
> 3. 检索结果按**产品名匹配 > 向量相似度**重排序,确保精准度
> 
> 这个设计解决了 RAG 系统的经典问题:**多文档信息混淆**。通过产品名归一化和优先级隔离,确保查询 A 产品不会返回 B 产品的条款。"

**追问应对**:
- **Q: 为什么不直接用向量检索?**  
  A: 向量检索依赖语义信息密度。产品名通常只有 4-6 字,信息熵太低,容易误匹配。精确匹配在短查询场景下准确率更高。

- **Q: 如何处理产品别名?**  
  A: 当前版本通过归一化处理(去空格、去标点)覆盖大部分变体。未来可扩展为产品别名表,在数据库层面维护。

---

### 亮点 3: 可追溯性设计 —— 生产级考量

**面试话术**:
> "这个项目的核心价值主张是**可追溯**——每个字段都标注来源条款 ID,用户可以点击查看原文。
> 
> 这不是技术炫技,而是**业务必需**:
> - 保险条款涉及法律责任,销售人员必须能验证信息来源
> - 可追溯性是防止 LLM 幻觉的最有效手段
> - 用户信任度直接影响产品采用率
> 
> 实现上,我们在 Prompt 中强制要求 LLM 输出 sourceClauseId,并在前端渲染为可点击的引用徽章。测试体系中有专门的**引用覆盖率指标**(目标 ≥90%),持续监控引用质量。
> 
> 这体现了 AI 产品的核心原则:**可控性优于智能性**。"

**数据支撑**:
- 引用覆盖率: 91.7% (超过目标 90%)
- 引用有效率: 100% (所有引用 ID 都能查到原文)
- 字段完整率: 95.8% (结构化抽取质量)

---

## 🔧 技术栈深度问答

### Next.js 相关

**Q: 为什么选择 Next.js 而不是纯后端框架?**
> "Next.js 提供了全栈开发的便利性:
> - API Routes 可以快速实现后端接口,无需单独部署
> - SSR/SSG 能力让首屏加载更快
> - 内置的文件路由和中间件简化开发
> 
> 对于 MVP 阶段,Next.js 的'一体化'特性让我能在 1-2 周内完成从前端到后端的完整交付。"

**Q: API Routes 的性能瓶颈是什么?**
> "主要瓶颈在于:
> 1. **冷启动**: Serverless 环境下首次请求可能较慢
> 2. **并发限制**: Vercel 免费版有并发数限制
> 3. **长连接**: 不适合 WebSocket 等长连接场景
> 
> 当前项目是低频查询场景,这些限制不是问题。如果未来需要高并发,可以迁移到独立部署。"

---

### Supabase + pgvector 相关

**Q: 为什么选择 Supabase 而不是传统向量数据库?**
> "Supabase 的优势是**一体化**:
> - PostgreSQL + pgvector 同时支持关系数据和向量检索
> - 不需要维护多个数据库
> - 自带 Auth、Storage、Realtime 等功能
> 
> 对于中小规模数据(当前 <100 个产品),pgvector 的性能完全够用。"

**Q: pgvector 的索引策略是什么?**
> "使用 HNSW 索引,平衡了检索速度和准确率。当前 P95 延迟 ≤3000ms,满足业务需求。"

---

### OpenAI API 相关

**Q: Embedding 模型选择的考量?**
> "当前使用 text-embedding-3-small (1536维),选择理由:
> 1. **成本**: 比 ada-002 便宜 5 倍
> 2. **性能**: 在中文场景下表现优于 ada-002
> 3. **维度**: 1536 维在 pgvector 中性能和准确率平衡较好"

**Q: 如何处理 Embedding 维度不一致的问题?**
> "这是 RAG 系统的经典坑。我们的解决方案:
> 1. **配置集中管理**: 维度在 .env 中统一定义
> 2. **启动时验证**: embeddings.ts 中有维度检查
> 3. **Schema 锁定**: 数据库表定义为 vector(1536),强制约束"

**Q: 如何控制 LLM 输出格式?**
> "使用 OpenAI 的 response_format: json_object 强制 JSON 输出。同时在 Prompt 中明确 JSON Schema 和示例。即使这样,仍有小概率返回非标准 JSON,所以代码中有 try-catch 兜底。"

---

## 📊 测试评估体系

### 6大核心指标详解

**面试话术**:
> "我们建立了**生产级的测试评估体系**,通过 6 大指标持续监控系统质量:
> 
> 1. **字段完整率 (95.8%)**: 验证结构化抽取是否完整
> 2. **引用覆盖率 (91.7%)**: 验证回答可追溯,非 LLM 幻觉
> 3. **引用有效率 (100%)**: 验证引用 ID 正确性
> 4. **P95 延迟 (≤3000ms)**: 验证性能可预测
> 5. **错误率 (≤5%)**: 验证系统稳定性
> 6. **稳定性得分 (100%)**: 验证同一产品多次查询结果一致"

### 测试集设计

**面试话术**:
> "测试集设计对齐真实用户行为:
> - **Group A (12条)**: 结构化字段完整性测试
> - **Group B (5条)**: 引用支持准确性测试
> - **Group C (3条)**: 稳定性测试
> 
> 关键设计决策:**不测试拒答场景**。因为前端下拉选择框已经消除了库外产品输入,测试重点应该在引用质量和抽取准确率上。"

---

## 🏗️ 工程能力体现

### 复利沉淀机制

**面试话术**:
> "项目中有个 experience/ 目录,记录了我踩过的坑和设计决策。这些文档不是事后总结,而是**开发过程中实时沉淀**的。每次遇到问题、做决策犹豫超过 30 分钟,就会更新文档。
> 
> 这个习惯让我在后续项目中能快速避坑,也让我在面试中能稳定表达设计思路。"

### 自动化工具链

**面试话术**:
> "项目中的 scripts/ 目录包含完整的自动化工具:
> - seed.ts: 一键导入产品数据 + 自动生成向量
> - eval-quality.ts: 质量评估 + 基线对比
> - regenerate-vectors.ts: 批量重新生成向量
> 
> 这些工具的设计原则是:**0-1 步操作,不需要人工干预**。"

---

## 💡 产品思维展示 (AI PM 岗位重点)

### 问题定义能力

**面试话术**:
> "这个项目最重要的不是技术实现,而是**问题定义**。
> 
> 最初的想法是做一个'保险问答机器人',但深入分析后发现:
> - 销售人员不需要回答零散问题,需要的是**完整的产品信息卡片**
> - 开放式问答会导致回答不完整
> - 拒答策略会消耗大量开发精力
> 
> 所以我们重新定义问题:**从问答系统变为信息提取系统**。这个转变让技术实现更简单,用户体验更好。"

### 取舍能力

**不做的功能**:
- ❌ 多轮对话: 业务场景不需要
- ❌ 个性化推荐: 数据量不足以支撑
- ❌ 复杂的用户画像: 过度工程

**做的功能**:
- ✅ 结构化信息提取: 核心价值
- ✅ 可追溯引用: 建立信任
- ✅ 缓存系统: 提升性能

---

## 🎤 常见面试问题速查

### 技术类

**Q: 如果数据量增长到百万级怎么办?**
> "当前架构支持到 10 万级产品。如果到百万级:
> 1. 向量数据库迁移到 Pinecone/Weaviate
> 2. 引入分片策略
> 3. 增加缓存层(Redis)
> 4. 考虑异步处理"

**Q: 如何防止 LLM 幻觉?**
> "三层防护:
> 1. **UI 约束**: 只允许选择已有产品
> 2. **引用机制**: 强制标注来源
> 3. **Fallback 规则**: 无法确定时填'条款未说明'而不是编造"

**Q: 如何优化成本?**
> "当前成本主要在 OpenAI API:
> 1. **缓存**: 相同查询直接返回,节省 API 调用
> 2. **模型选择**: 使用 gpt-4o-mini 而非 gpt-4
> 3. **Prompt 优化**: 减少 token 使用
> 
> 单次查询成本约 0.01-0.02 元,可接受。"

**Q: 为什么用 UI 约束而不是 prompt 拒答?**
> "Prompt 拒答有三个核心问题:
> 1. **不稳定**: LLM 有概率突破 prompt 约束
> 2. **成本高**: 每次都要消耗 token 来判断是否拒答
> 3. **体验差**: 用户输入后才被拒绝,浪费时间
> 
> UI 约束从根本上消除问题:用户只能选择已有产品,不存在'是否拒答'的判断。
> 这是**设计层面的解决方案**,比技术层面更优雅。"

**Q: 缓存失效策略是什么?**
> "采用**主动失效 + TTL 兜底**的双重策略:
> 1. **主动失效**: 产品启用/禁用时,自动清除该产品缓存
> 2. **TTL 兜底**: 所有缓存 24 小时过期
> 3. **按产品名缓存**: 缓存键是归一化后的产品名,不是用户查询
> 
> 选择这个策略因为保险条款更新频率低(月级),24 小时 TTL 足够。
> 同时主动失效保证了产品状态变更时的**最终一致性**。"

**Q: 如果要支持 10 万用户,你会改什么?**
> "从架构角度,需要改进:
> 1. **缓存层**: 从 Supabase 表迁移到 Redis,支持更高 QPS
> 2. **向量数据库**: 考虑 Pinecone/Weaviate 专业方案
> 3. **API 网关**: 加入限流、熔断机制
> 4. **CDN**: 静态资源全球分发
> 5. **监控告警**: 接入 Prometheus + Grafana
> 
> 当前 MVP 架构能支撑 1000-5000 用户,足够验证产品价值。"

---

### 产品类

**Q: 如何衡量产品成功?**
> "核心指标:
> 1. **效率提升**: 查询时间从 10-30 分钟降到 10-30 秒
> 2. **准确率**: 引用覆盖率 ≥90%
> 3. **用户满意度**: NPS 或满意度调研
> 4. **使用频率**: DAU/MAU"

**Q: 如果用户反馈信息不准确怎么办?**
> "处理流程:
> 1. **定位问题**: 是检索问题还是生成问题
> 2. **追溯来源**: 通过 sourceClauseId 定位原始条款
> 3. **修正数据**: 更新条款或重新生成向量
> 4. **记录模式**: 更新 experience/ 文档"

---

### 行为类

**Q: 遇到最大的技术挑战是什么?**
> "Embedding 维度不一致导致检索失败。最初数据库定义 1536 维,但实际模型输出 3072 维。
> 
> 解决过程:
> 1. 通过日志定位问题
> 2. 统一配置管理
> 3. 添加启动验证
> 4. 沉淀为 rag_error_patterns.md 模式 1
> 
> 这个经历让我意识到**配置一致性**在分布式系统中的重要性。"

**Q: 如何平衡快速交付和代码质量?**
> "我的原则是:**MVP 阶段优先交付,但保留重构空间**。
> 
> 具体做法:
> 1. 核心逻辑写清晰,边缘功能可以简化
> 2. 关键决策写注释,方便后续重构
> 3. 测试覆盖核心路径,不追求 100% 覆盖
> 4. 定期 code review,识别技术债"

---

## 📝 项目数据速查表

| 指标 | 数值 | 说明 |
|------|------|------|
| 技术栈 | Next.js 15 + Supabase + OpenAI | 全栈方案 |
| 开发周期 | 2-3 周 | MVP 到生产就绪 |
| 代码量 | ~3000 行 | 不含 node_modules |
| 测试用例 | 20 条 | 覆盖核心场景 |
| 字段完整率 | 95.8% | 结构化抽取质量 |
| 引用覆盖率 | 91.7% | 可追溯性 |
| P95 延迟 | ≤3000ms | 性能指标 |
| 错误率 | ≤5% | 稳定性指标 |
| 产品数量 | 10+ | 当前数据规模 |
| 单次查询成本 | 0.01-0.02 元 | OpenAI API |

---

## 🎯 面试前检查清单

- [ ] 能流畅讲述 3 个核心亮点
- [ ] 能解释混合检索的实现逻辑
- [ ] 能说明 6 大指标的含义和目标值
- [ ] 准备好 1-2 个技术挑战的故事
- [ ] 准备好产品取舍的案例
- [ ] 复习 experience/ 文档中的设计原则
- [ ] 准备好项目 Demo 演示
- [ ] 能回答"为什么不用 XXX 技术"

---

## 💼 不同岗位的侧重点

### AI 工程师岗位
- **强调**: 混合检索、向量索引、Prompt 工程
- **准备**: 代码细节、性能优化、技术选型

### AI 产品经理岗位
- **强调**: 问题定义、产品取舍、用户价值
- **准备**: 业务场景、指标设计、产品迭代

### 全栈工程师岗位
- **强调**: 端到端交付、工程能力、自动化
- **准备**: 架构设计、测试体系、部署流程

---

**最后提醒**: 面试时保持自信,诚实表达。不知道的问题说"不知道",但可以说"我会这样去学习"。展示学习能力和解决问题的思路,比死记硬背更重要。
