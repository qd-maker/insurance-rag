# 保险 RAG 项目知识点清单

> **定位**: 面试前的知识点自查表  
> **使用方式**: 逐条检查,确保每个知识点都能用自己的话解释

---

## 🎯 核心技术知识点

### 1. RAG (检索增强生成) 基础

#### 必须掌握 (P0)

**Q: 什么是 RAG?**
- [ ] 能解释 RAG 的三个步骤: Retrieval → Augmentation → Generation
- [ ] 能说明 RAG 与纯 LLM 的区别
- [ ] 能举例说明 RAG 的应用场景

**标准答案**:
> RAG 是一种结合检索和生成的技术。工作流程是:
> 1. **Retrieval**: 根据用户查询,从知识库中检索相关文档
> 2. **Augmentation**: 将检索到的文档作为上下文,增强 Prompt
> 3. **Generation**: LLM 基于增强后的 Prompt 生成回答
> 
> 相比纯 LLM,RAG 的优势是:
> - 可以访问最新信息 (不受训练数据时间限制)
> - 回答可追溯 (能标注来源)
> - 减少幻觉 (基于真实文档)

---

**Q: RAG 的核心挑战是什么?**
- [ ] 能说出至少 3 个挑战
- [ ] 能解释你的项目如何应对这些挑战

**标准答案**:
> 核心挑战:
> 1. **检索准确性**: 如何找到真正相关的文档
> 2. **信息混淆**: 多文档场景下如何避免跨文档污染
> 3. **幻觉控制**: 如何防止 LLM 编造不存在的信息
> 4. **性能优化**: 如何在延迟和准确率之间平衡
> 
> 我的项目应对:
> - 混合检索策略 (精确匹配 + 语义检索)
> - 产品级隔离 (优先级过滤)
> - 强制引用机制 (sourceClauseId)
> - 缓存系统 (降低延迟)

---

### 2. Embedding (向量嵌入)

#### 必须掌握 (P0)

**Q: 什么是 Embedding?**
- [ ] 能解释文本 → 向量的过程
- [ ] 能说明为什么需要向量化
- [ ] 能举例说明向量相似度的计算

**标准答案**:
> Embedding 是将文本转换为数值向量的过程。
> 
> 原理:
> - 通过预训练模型 (如 text-embedding-3-small) 将文本映射到高维空间
> - 语义相似的文本在向量空间中距离更近
> - 向量维度通常为 1536 或 3072
> 
> 相似度计算:
> - **余弦相似度**: 计算两个向量的夹角,范围 [-1, 1]
> - **欧氏距离**: 计算两个向量的直线距离
> 
> 我的项目使用余弦相似度,因为它对向量长度不敏感。

---

**Q: 如何选择 Embedding 模型?**
- [ ] 能对比至少 2 个模型
- [ ] 能解释你的项目为什么选择当前模型

**标准答案**:
> 常见模型对比:
> 
> | 模型 | 维度 | 成本 | 中文表现 |
> |------|------|------|----------|
> | text-embedding-ada-002 | 1536 | 高 | 一般 |
> | text-embedding-3-small | 1536 | 低 | 好 |
> | text-embedding-3-large | 3072 | 中 | 很好 |
> 
> 我的项目选择 text-embedding-3-small 因为:
> - 成本比 ada-002 低 5 倍
> - 中文场景表现更好
> - 1536 维在 pgvector 中性能平衡

---

**Q: Embedding 维度不一致会导致什么问题?**
- [ ] 能说明问题的严重性
- [ ] 能解释如何避免这个问题

**标准答案**:
> 问题:
> - 向量写入失败 (数据库 Schema 不匹配)
> - 检索返回空结果 (维度不一致无法计算相似度)
> - 系统静默失败 (没有明确报错)
> 
> 避免方法:
> 1. **配置集中管理**: 维度在 .env 中统一定义
> 2. **启动时验证**: embeddings.ts 中检查实际维度
> 3. **Schema 锁定**: 数据库表定义为 vector(1536)
> 
> 这是我踩过的第一个坑,沉淀在 rag_error_patterns.md 模式 1。

---

### 3. 向量数据库

#### 必须掌握 (P0)

**Q: 为什么需要向量数据库?**
- [ ] 能解释向量检索的特殊性
- [ ] 能说明传统数据库的局限

**标准答案**:
> 向量数据库的必要性:
> - **高维检索**: 传统数据库不支持高维向量的相似度搜索
> - **性能优化**: 向量数据库有专门的索引 (如 HNSW)
> - **规模化**: 支持百万级向量的快速检索
> 
> 传统数据库局限:
> - 只能做精确匹配或模糊匹配
> - 无法理解语义相似性
> - 高维向量检索性能差

---

**Q: pgvector vs Pinecone vs Weaviate?**
- [ ] 能对比至少 2 个方案
- [ ] 能解释你的项目为什么选择 pgvector

**标准答案**:
> | 方案 | 优势 | 劣势 | 适用场景 |
> |------|------|------|----------|
> | pgvector | 一体化 (关系+向量) | 性能不如专业向量库 | 中小规模 |
> | Pinecone | 性能强、易用 | 成本高、依赖外部服务 | 大规模生产 |
> | Weaviate | 开源、功能全 | 运维复杂 | 自建方案 |
> 
> 我的项目选择 pgvector 因为:
> - 数据规模小 (<100 产品),性能够用
> - 与 Supabase 一体化,不需要维护多个数据库
> - 降低技术复杂度,快速交付

---

### 4. Prompt Engineering

#### 必须掌握 (P0)

**Q: 如何设计一个好的 Prompt?**
- [ ] 能说出至少 3 个原则
- [ ] 能举例说明你的项目中的 Prompt 设计

**标准答案**:
> 好 Prompt 的原则:
> 1. **明确角色**: "你是一个保险信息抽取助手"
> 2. **清晰指令**: "请基于条款上下文,提取结构化信息"
> 3. **约束输出**: "只输出 JSON,不要任何多余文本"
> 4. **提供示例**: 给出期望的输出格式
> 5. **Fallback 规则**: "如果无法确定,填 null 而不是编造"
> 
> 我的项目 Prompt (search/route.ts 304-334行):
> - 系统角色明确
> - JSON Schema 清晰
> - 强制引用机制 (sourceClauseId)
> - Fallback 规则 (条款未说明)

---

**Q: 如何控制 LLM 输出格式?**
- [ ] 能说出至少 2 种方法
- [ ] 能解释你的项目使用的方法

**标准答案**:
> 控制输出格式的方法:
> 1. **JSON Mode**: OpenAI 的 response_format: json_object
> 2. **Few-shot**: 在 Prompt 中提供示例
> 3. **后处理**: 代码层面解析和验证
> 4. **Function Calling**: OpenAI 的函数调用机制
> 
> 我的项目使用:
> - JSON Mode 强制 JSON 输出
> - Prompt 中明确 Schema
> - try-catch 兜底处理非标准 JSON

---

### 5. 混合检索策略

#### 必须掌握 (P0)

**Q: 什么是混合检索?**
- [ ] 能解释混合检索的概念
- [ ] 能说明为什么需要混合检索

**标准答案**:
> 混合检索是结合多种检索方法的策略:
> - **精确匹配**: 基于字符串相等或包含关系
> - **语义检索**: 基于向量相似度
> - **重排序**: 根据业务规则调整结果顺序
> 
> 需要混合检索的原因:
> - 短查询 (产品名) 信息熵低,纯向量检索容易误匹配
> - 长查询 (描述) 需要语义理解,精确匹配不够
> - 业务规则 (产品优先级) 需要人工干预
> 
> 我的项目实现:
> 1. 产品名归一化 + 精确匹配
> 2. 向量语义检索
> 3. 按产品匹配优先级重排序

---

**Q: 如何处理多文档信息混淆?**
- [ ] 能说明问题的本质
- [ ] 能解释你的项目的解决方案

**标准答案**:
> 问题本质:
> - 向量检索只看相似度,不考虑文档边界
> - 查询 A 产品可能返回 B 产品的条款
> - 用户体验差,信任度低
> 
> 解决方案:
> 1. **完全隔离**: 先确定产品,再检索该产品的条款
> 2. **优先级过滤**: 匹配产品的条款优先,其他降权
> 3. **重排序**: 按产品匹配度 > 向量相似度排序
> 
> 我的项目使用完全隔离:
> - 产品名匹配成功后,只保留该产品的条款
> - 避免跨产品污染

---

### 6. 可追溯性设计

#### 必须掌握 (P0)

**Q: 为什么需要可追溯性?**
- [ ] 能说明业务必要性
- [ ] 能解释技术实现

**标准答案**:
> 业务必要性:
> - 保险条款涉及法律责任,必须能验证来源
> - 防止 LLM 幻觉,建立用户信任
> - 方便人工审核和纠错
> 
> 技术实现:
> 1. **Prompt 强制**: 要求 LLM 输出 sourceClauseId
> 2. **数据结构**: 每个字段都有 { value, sourceClauseId }
> 3. **前端渲染**: 引用徽章可点击查看原文
> 4. **测试验证**: 引用覆盖率指标 (目标 ≥90%)
> 
> 我的项目引用覆盖率 91.7%,引用有效率 100%。

---

## 🔧 工程实践知识点

### 7. 测试评估体系

#### 必须掌握 (P0)

**Q: 如何评估 RAG 系统的质量?**
- [ ] 能说出至少 4 个指标
- [ ] 能解释每个指标的含义

**标准答案**:
> 6 大核心指标:
> 
> 1. **字段完整率**: 结构化抽取是否完整
>    - 计算: 非空字段数 / 总字段数
>    - 目标: ≥95%
> 
> 2. **引用覆盖率**: 字段是否有来源标注
>    - 计算: 有 sourceClauseId 的字段数 / 总字段数
>    - 目标: ≥90%
> 
> 3. **引用有效率**: 引用 ID 是否正确
>    - 计算: 有效引用数 / 总引用数
>    - 目标: 100%
> 
> 4. **P95 延迟**: 95% 请求的响应时间
>    - 目标: ≤3000ms
> 
> 5. **错误率**: 请求失败比例
>    - 目标: ≤5%
> 
> 6. **稳定性得分**: 同一查询多次结果一致性
>    - 目标: ≥95%

---

**Q: 如何设计测试集?**
- [ ] 能说明测试集的设计原则
- [ ] 能解释你的项目的测试集

**标准答案**:
> 设计原则:
> - **对齐真实场景**: 测试用例来自真实用户行为
> - **覆盖核心功能**: 不追求 100% 覆盖,聚焦核心路径
> - **可量化验证**: 每个用例有明确的验收标准
> 
> 我的项目测试集 (20 条):
> - **Group A (12条)**: 结构化字段完整性
> - **Group B (5条)**: 引用支持准确性
> - **Group C (3条)**: 稳定性测试
> 
> 不测试拒答场景,因为 UI 强约束已消除该问题。

---

### 8. 性能优化

#### 必须掌握 (P0)

**Q: RAG 系统的性能瓶颈在哪?**
- [ ] 能说出至少 3 个瓶颈
- [ ] 能解释优化方法

**标准答案**:
> 性能瓶颈:
> 1. **Embedding 生成**: 每次查询都要调用 API
> 2. **向量检索**: 高维向量计算耗时
> 3. **LLM 生成**: 大模型推理慢
> 4. **网络延迟**: 多次 API 调用
> 
> 优化方法:
> 1. **缓存**: 相同查询直接返回结果
> 2. **索引优化**: 使用 HNSW 索引
> 3. **模型选择**: 用 gpt-4o-mini 而非 gpt-4
> 4. **批量处理**: 减少 API 调用次数
> 
> 我的项目优化:
> - 缓存系统 (24小时过期)
> - HNSW 索引
> - gpt-4o-mini (成本和速度平衡)

---

### 9. 错误处理

#### 必须掌握 (P0)

**Q: RAG 系统常见的错误场景?**
- [ ] 能说出至少 3 个场景
- [ ] 能解释处理策略

**标准答案**:
> 常见错误场景:
> 1. **API 调用失败**: OpenAI API 超时或限流
> 2. **检索无结果**: 查询与知识库不匹配
> 3. **LLM 输出格式错误**: 返回非 JSON
> 4. **维度不一致**: Embedding 维度与数据库不匹配
> 
> 处理策略:
> 1. **重试机制**: API 失败自动重试
> 2. **Fallback**: 检索无结果时返回友好提示
> 3. **兜底解析**: try-catch 处理非标准输出
> 4. **启动验证**: 系统启动时检查配置一致性
> 
> 我的项目实现:
> - search/route.ts 有完整的 try-catch
> - 检索无结果返回 notFound 对象
> - JSON 解析失败有默认结构兜底

---

### 10. 自动化工具

#### 必须掌握 (P0)

**Q: 为什么需要自动化工具?**
- [ ] 能说明自动化的价值
- [ ] 能举例你的项目中的工具

**标准答案**:
> 自动化的价值:
> - **降低人工成本**: 不需要技术人员介入
> - **减少错误**: 避免手动操作失误
> - **提高效率**: 一键完成复杂流程
> - **可复现**: 流程标准化,结果一致
> 
> 我的项目工具:
> 1. **seed.ts**: 一键导入产品 + 生成向量
> 2. **eval-quality.ts**: 质量评估 + 基线对比
> 3. **regenerate-vectors.ts**: 批量重新生成向量
> 
> 设计原则: 0-1 步操作,不需要人工干预。

---

## 💡 产品思维知识点

### 11. 问题定义

#### 必须掌握 (P0)

**Q: 如何定义一个好的产品问题?**
- [ ] 能说出问题定义的原则
- [ ] 能举例你的项目的问题定义

**标准答案**:
> 问题定义原则:
> 1. **用户视角**: 从用户痛点出发,不是技术可行性
> 2. **可量化**: 能用数据衡量问题的严重性
> 3. **可解决**: 在资源和时间约束下可实现
> 4. **有价值**: 解决后能带来明显改善
> 
> 我的项目问题定义:
> - **原问题**: 销售人员查阅保险条款效率低
> - **量化**: 10-30 分钟/次,每天查询 5-10 次
> - **解决方案**: RAG 信息提取系统
> - **价值**: 时间缩短到 10-30 秒,效率提升 60 倍

---

### 12. 产品取舍

#### 必须掌握 (P0)

**Q: 如何做产品功能的取舍?**
- [ ] 能说出取舍的原则
- [ ] 能举例你的项目中的取舍

**标准答案**:
> 取舍原则:
> 1. **MVP 优先**: 先做核心功能,不追求完美
> 2. **用户感知**: 3 分钟内感知不到的功能不做
> 3. **成本收益**: 开发成本 vs 用户价值
> 4. **技术风险**: 不确定性高的功能降级
> 
> 我的项目取舍:
> 
> **不做的功能**:
> - ❌ 多轮对话: 业务场景不需要
> - ❌ 个性化推荐: 数据量不足
> - ❌ 复杂用户画像: 过度工程
> 
> **做的功能**:
> - ✅ 结构化信息提取: 核心价值
> - ✅ 可追溯引用: 建立信任
> - ✅ 缓存系统: 提升性能

---

## ✅ 自检清单

### 技术深度
- [ ] 能用自己的话解释 RAG 工作原理
- [ ] 能画出系统架构图
- [ ] 能讲清楚混合检索的实现
- [ ] 能解释 Embedding 维度不一致的问题
- [ ] 能说明 6 大质量指标的含义

### 代码细节
- [ ] 能讲清楚产品名归一化函数
- [ ] 能解释混合检索的代码逻辑
- [ ] 能说明 Prompt 的设计思路
- [ ] 能讲清楚缓存系统的实现
- [ ] 能解释错误处理的策略

### 产品思维
- [ ] 能说明问题定义的过程
- [ ] 能解释产品取舍的逻辑
- [ ] 能量化产品价值
- [ ] 能提出改进方向
- [ ] 能回答"为什么这样设计"

### 工程能力
- [ ] 能说明测试体系的设计
- [ ] 能解释自动化工具的价值
- [ ] 能讲清楚复利沉淀机制
- [ ] 能说明性能优化的方法
- [ ] 能回答"如何保证质量"

---

## 🎯 面试前最后检查

**前一天晚上**:
- [ ] 过一遍这个清单,确保每个知识点都能讲
- [ ] 准备好项目 Demo
- [ ] 复习面试指南中的话术
- [ ] 调整心态,早点休息

**面试当天**:
- [ ] 提前 10 分钟到场/上线
- [ ] 准备好纸笔 (画架构图)
- [ ] 打开项目代码 (可能要看)
- [ ] 深呼吸,保持自信

**记住**: 不知道的问题诚实说"不知道",但可以说"我会这样去学习"。展示学习能力和解决问题的思路,比死记硬背更重要。
