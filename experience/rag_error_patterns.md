# RAG 系统开发通用错误模式与解决方案（Engineering Edition）

> **定位**  
> 本文档用于沉淀 RAG（Retrieval-Augmented Generation）系统的**通用工程经验与设计方法论**，  
> 不绑定具体项目或技术栈，用于指导 **人类 + AI 的联合决策**。

> **优先级声明**  
> 当 AI 的建议与本文档规则发生冲突时，**以本文档为准**。

> **使用方式**  
> - 设计阶段：作为 RAG 架构决策参考  
> - 开发阶段：用于 Debug / 排错  
> - 面试阶段：用于稳定表述与设计解释  
> - AI 协作：作为长期上下文 @ 引用

---

## 模式 1：Embedding 维度不一致

### 问题本质
在 RAG 系统中，向量的 **生成 / 存储 / 检索** 必须使用**完全一致的维度**。  
任一环节不一致，系统将直接失效或产生隐性错误。

### 常见触发场景
- 数据库 Schema 定义为 `vector(1536)`
- Embedding 模型切换后实际输出为 `1024` 维
- 开发 / 测试 / 生产环境使用不同模型
- Embedding Provider 自动升级模型版本

### 典型信号（Debug 线索）
- 向量写入失败或静默失败
- 检索返回为空，但数据确认已写入
- 同样代码在不同环境行为不一致

### 通用解决思路

**设计原则**
1. **单一真实来源（SSOT）**：维度只在一个地方定义
2. **启动时验证**：系统启动即校验，不依赖人工发现
3. **Schema 锁定**：数据库层面明确约束

**实现模式（示意）**
```ts
// config.ts
export const CONFIG = {
  EMBEDDING_MODEL: 'text-embedding-ada-002',
  EMBEDDING_DIM: 1536,
};

// 启动校验
async function validateEmbeddingConfig() {
  const embed = await generateEmbedding('test');
  if (embed.length !== CONFIG.EMBEDDING_DIM) {
    throw new Error(
      `Embedding 维度不匹配：期望 ${CONFIG.EMBEDDING_DIM}，实际 ${embed.length}`
    );
  }
}
````

```sql
-- Schema 显式锁定维度
CREATE TABLE embeddings (
  id BIGSERIAL PRIMARY KEY,
  embedding vector(1536) NOT NULL
);
```

### 检查清单

* [ ] 维度在配置中集中定义
* [ ] Schema 使用固定维度
* [ ] Embedding 生成使用同一模型
* [ ] 启动阶段自动校验维度

---

## 模式 2：短查询 vs 长查询的检索策略失配

### 问题本质

向量检索依赖语义信息密度。
**信息熵过低的短查询**（尤其是产品名、关键词）无法提供足够语义信号。

### 常见触发场景

* 用户输入产品名（如 4–6 字），返回错误产品
* 用户输入完整描述（30+ 字），检索准确

### 判断标准（经验）

* **短查询**：信息熵低（通常 <8–12 字，需结合语言与业务判断）
* **长查询**：包含多个语义要素（需求 + 约束 + 场景）

### 通用解决思路

**混合检索决策树**

```
查询输入
 ├─ 信息熵低（短查询）
 │   ├─ 精确匹配（ID / 产品名）
 │   ├─ 归一化字符串匹配
 │   └─ 向量检索作为补充
 └─ 信息熵高（长查询）
     ├─ 向量语义检索优先
     └─ 关键词匹配作为过滤
```

**归一化通用模式**

```ts
function normalize(text: string): string {
  return text
    .toLowerCase()
    .normalize('NFKC')
    .replace(/[\s\u3000]/g, '')
    .replace(/[^\w\u4e00-\u9fa5]/g, '');
}
```

**重排序优先级**

```
精确匹配 > 部分匹配 > 向量相似度
```

---

## 模式 3：信息粒度 vs 信息完整性的错误权衡

### 问题本质

RAG 的核心矛盾：

* **细粒度** → 检索精准，但上下文易丢失
* **粗粒度** → 信息完整，但相似度不够锐利

### 常见错误做法（反模式）

```ts
// ❌ 让 LLM “提取关键信息”
const summary = await llm.summarize(fullContent);
// 数字、比例、条件大量丢失
```

### 核心原则

> **宁可召回冗余信息，也不要丢失关键信息**

### 决策矩阵

| 场景      | 推荐策略     | 理由     |
| ------- | -------- | ------ |
| 法律 / 条款 | 粗粒度 + 原文 | 错误成本极高 |
| 产品规则    | 粗粒度 + 原文 | 数值不可压缩 |
| 新闻内容    | 细粒度      | 主题优先   |
| 技术文档    | 中等粒度     | 结构清晰   |

### 粗粒度优化手段

* 提升 Embedding 质量
* 增加元数据过滤
* 关键词 + 向量混合检索

---

## 模式 4：多文档 / 多产品信息混淆

### 问题本质

当系统包含多个逻辑独立的文档或产品时，
**默认的向量相似度排序会导致跨文档污染**。

### 典型信号

* 查询 A 产品，返回 B 产品条款
* 回答引用来源不一致

### 隔离级别策略

**Level 1：完全隔离（强推荐）**

* 适用：产品 / 合同 / 明确对象
* 策略：先确定对象，再检索

**Level 2：优先级隔离**

* 适用：相关文档族
* 策略：目标文档优先，其余降权

**Level 3：无隔离**

* 适用：知识库 / 探索性查询

---

## 模式 5：用户操作步骤过多导致系统不可用

### 问题本质

复杂流程 = 用户一定会漏一步。

### 自动化金字塔

```
0 步：全自动（理想）
1 步：一键命令（可接受）
2–3 步：需优化
4+ 步：不可接受
```

### 工程原则

* 自动检测依赖
* 原子化操作
* 幂等性执行

---

## 模式 6：配置管理失控

### 问题本质

多环境、多入口配置导致**真实生效配置不透明**。

### 最佳实践

**优先级明确**

```
环境变量 > .env.local > .env > 默认值
```

**单一加载点**

```ts
// config.ts
export const config = {
  embedding: {
    model: process.env.EMBEDDING_MODEL ?? 'text-embedding-ada-002',
    dim: Number(process.env.EMBEDDING_DIM ?? 1536),
  },
};
```

**启动时验证**

```ts
function validateConfig() {
  const required = ['OPENAI_API_KEY', 'SUPABASE_URL'];
  const missing = required.filter(k => !process.env[k]);
  if (missing.length) {
    throw new Error(`缺少必需配置: ${missing.join(', ')}`);
  }
}
```

---

## 反模式：不应该使用 RAG 的场景（重要）

* 规则可穷举（if / else 更可靠）
* 数据量极小且稳定（<50 条）
* 错误成本极高（医疗 / 核心法律判断）
* 查询意图高度固定（下拉框可解决）

> **结论**：RAG 不是默认方案，而是最后一公里方案。

---

## 通用调试流程（强制执行）

```
1. 明确症状（具体错误）
2. 隔离变量（最小复现）
3. 验证假设（脚本 / 测试）
4. 回归验证
5. 记录为模式
```

---

## RAG 系统快速检查清单

### 设计阶段

* [ ] 是否真的需要 RAG
* [ ] 粒度策略是否明确
* [ ] 隔离策略是否定义

### 实施阶段

* [ ] 维度一致性验证
* [ ] 配置集中管理
* [ ] 自动化流程

### 测试阶段

* [ ] 短查询 / 长查询测试
* [ ] 跨文档污染验证
* [ ] 向量覆盖率检查

---

## RAG 设计哲学（长期有效）

1. **简单优于复杂**
2. **验证优于假设**
3. **自动化优于手动**
4. **明确优于隐式**

> 好的 RAG 系统不是功能最多的，而是**最不容易出错的**。

```

---

### 给你一句**非常重要的使用建议**
👉 **这个文件以后只做三件事：**
- 新模式 → 加一节
- 老模式 → 补“典型信号”
- 被面试问住 → 回来补规则

**不重写、不推翻，只增量进化。**
